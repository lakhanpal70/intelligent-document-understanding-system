ğŸ§  End-to-End AI System for Intelligent Document Understanding and Automated Decision-Making
ğŸš€ Overview

This project implements an AI-powered document understanding system capable of reading, extracting, and interpreting data from unstructured business documents such as resumes, invoices, and reports.

The system combines OCR, NLP, and machine learning models to automate document classification, field extraction, and decision-making â€” reducing manual review time and improving data accuracy.

<img width="682" height="684" alt="image" src="https://github.com/user-attachments/assets/a3b642ba-8b2d-4f15-8491-aaed5eee36e3" />

          


# Technical report


âš™ï¸ Features
1ï¸âƒ£ Save uploaded file 2ï¸âƒ£ OCR text extraction 3ï¸âƒ£ Document type detection 4ï¸âƒ£ Key field extraction 5ï¸âƒ£ Automated decision-making 6ï¸âƒ£ Explainability visualization


âœ… Intelligent document parsing and text extraction
âœ… Named Entity Recognition (NER) for field detection
âœ… Resume and invoice understanding
âœ… Decision-making pipeline (accept/reject logic)
âœ… REST API with FastAPI
âœ… Interactive web frontend for document upload and result visualization
âœ… Dockerized deployment

ğŸ—ï¸ System Architecture

â”ŒFrontend UI (HTML / CSS / JS)
          â”‚
          â–¼
FastAPI API (Python Backend)
          â”‚
          â–¼
Document Processing (PyMuPDF, OCR, NLP)
          â”‚
          â–¼
ML / NLP Model (Trained Checkpoints)
          â”‚
          â–¼
Decision Generator (Rule-based / ML)





ğŸ§  Model Pipeline

Preprocessing â€“ Text extraction from PDFs/images

Feature Extraction â€“ NLP-based entity tagging and vectorization

Model Training â€“ Using Transformer-based architecture (BERT / LayoutLM)

Evaluation â€“ Accuracy, Precision, Recall, and F1 Score

Inference API â€“ Serve model via FastAPI



ğŸ§ª Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/lakhanpal70/intelligent-document-understanding-system.git
cd intelligent-document-understanding-system

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/bin/activate   # (Linux/Mac)
.venv\Scripts\activate      # (Windows)

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the Backend (FastAPI)
uvicorn api.main:app --reload


Open in browser â†’ http://127.0.0.1:8000/docs

5ï¸âƒ£ Run the Frontend

Open frontend/index.html in your browser.

ğŸ³ Docker Deployment

Build and run using Docker:

docker build -t intelligent-doc-ai .
docker run -p 8000:8000 intelligent-doc-ai

ğŸ“˜ Dataset Description

Used a combination of synthetic and publicly available datasets (resumes, invoices, ID cards) to train and evaluate models for text extraction and structured field understanding.

ğŸ“ˆ Results & Future Improvements

âœ… Achieved high accuracy in field extraction and classification
âœ… Scalable API for production use

ğŸ”® Future Enhancements:

Fine-tune transformer models with more diverse data

Add support for multilingual document processing

Integrate advanced OCR (Tesseract + LayoutLMv3)

Deploy on cloud (AWS / Render / HuggingFace Spaces)

ğŸ‘¨â€ğŸ’» Author

Lakhan Pal
AI Developer | Machine Learning Engineer
ğŸ“§ lakhanpal7400@gmail.com

ğŸªª License

This project is licensed under the MIT License
.
